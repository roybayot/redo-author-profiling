{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from scipy import stats\n",
    "\n",
    "import re\n",
    "\n",
    "reload(sys)\n",
    "#sys.setdefaultencoding(\"ISO-8859-1\")\n",
    "sys.setdefaultencoding(\"UTF-8\")\n",
    "\n",
    "defaultFileNames = {'age': 'age-important-words-using-info-gain.txt',\n",
    "                    'gender': 'gender-important-words-using-info-gain.txt'\n",
    "                   }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(raw_text):\n",
    "    review_text = BeautifulSoup(raw_text).get_text()\n",
    "    words = review_text.lower().split()\n",
    "    return(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_all_text(allText, numLines):\n",
    "    clean_train_data = []\n",
    "    for i in xrange(0, numLines):\n",
    "        clean_train_data.append(clean_text(allText[i]))\n",
    "    return clean_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def featureSelection(train_x, task, train_y):\n",
    "    rows, cols = train_x.shape\n",
    "    top_info_words_numbers = [100, 200, 300, 500, 700, 1000, 2000, 5000, 7000, 8000, 9000, 10000, cols-1]\n",
    "    top_info_words_numbers =  sorted(top_info_words_numbers, reverse=True)\n",
    "\n",
    "    feature_selection_result = {}\n",
    "    \n",
    "    task_to_filenames = {'age': ['age-important-words-using-info-gain.txt', \n",
    "                                 'age-important-words-using-gain-ratio.txt'],\n",
    "                         'gender': ['gender-important-words-using-info-gain.txt', \n",
    "                                    'gender-important-words-using-gain-ratio.txt']\n",
    "                        }\n",
    "    \n",
    "    task_to_filenames = {'age': ['age-important-words-using-info-gain.txt'],\n",
    "                         'gender': ['gender-important-words-using-info-gain.txt']\n",
    "                        }\n",
    "    \n",
    "    filenames = task_to_filenames[task]\n",
    "    for filename in filenames:\n",
    "        with open(filename) as f:\n",
    "            alist = [line.rstrip() for line in f]\n",
    "        all_indices_ranked = alist[0].split(',')\n",
    "        all_indices_ranked = [int(x) for x in all_indices_ranked]\n",
    "        all_indices_ranked = [x-1 for x in all_indices_ranked]\n",
    "        \n",
    "        list_of_scores = []\n",
    "        for num_info_words in top_info_words_numbers:\n",
    "            clf = svm.SVC(kernel='linear', C=1)\n",
    "            scoring_function = 'accuracy'\n",
    "            \n",
    "            xx = [all_indices_ranked[x] for x in range(0, num_info_words)]\n",
    "            xx = tuple(xx)\n",
    "            smaller_train_x = train_x[:, xx]\n",
    "\n",
    "            scores = cross_validation.cross_val_score(clf, smaller_train_x, train_y, cv=10, scoring=scoring_function)\n",
    "            list_of_scores.append(scores)\n",
    "            \n",
    "            feature_selection_result[filename] = list_of_scores\n",
    "    return feature_selection_result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doSVMwithRBF(smaller_train_x, train_y, task):\n",
    "    params = {'age': {'gammas': [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4],\n",
    "                      'C': [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4]},\n",
    "              'gender': {'gammas': [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4],\n",
    "                      'C': [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4]}\n",
    "             }\n",
    "    \n",
    "    gammas = params[task]['gammas']\n",
    "    C = params[task]['C']\n",
    "    \n",
    "    list_of_scores = []\n",
    "    results_with_params = {}\n",
    "    \n",
    "    for g in gammas:\n",
    "        for one_C in C:\n",
    "            clf = svm.SVC(kernel='rbf', gamma=g, C=one_C)\n",
    "            scoring_function = 'accuracy'\n",
    "            scores = cross_validation.cross_val_score(clf, smaller_train_x, train_y, cv=10, scoring=scoring_function)\n",
    "            list_of_scores.append(scores)\n",
    "            label = str(g)+','+str(one_C)\n",
    "            results_with_params[label] = scores\n",
    "    \n",
    "    svm_rbf_result_list_of_scores = list_of_scores\n",
    "    \n",
    "    return svm_rbf_result_list_of_scores, results_with_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculatePValue(input_dictionary):\n",
    "    p_values_dictionary = {}\n",
    "    for each_key in input_dictionary.keys():\n",
    "        list_of_scores = input_dictionary[each_key]\n",
    "        i = range(0,len(list_of_scores))\n",
    "        list_of_pvalues = []\n",
    "        for x, i  in zip(list_of_scores,i):\n",
    "            z_stat, p_val = stats.ranksums(list_of_scores[0], x)\n",
    "            list_of_pvalues.append( p_val)\n",
    "        p_values_dictionary[each_key] = list_of_pvalues\n",
    "    return p_values_dictionary        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAccuracies(feature_selection_result):\n",
    "    accuracies_dictionary = {}\n",
    "    for each_key in feature_selection_result.keys():\n",
    "        list_of_accuracies = feature_selection_result[each_key]\n",
    "        accuracies = [a.mean() for a in list_of_accuracies]\n",
    "        accuracies_dictionary[each_key] = accuracies\n",
    "    return accuracies_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getListOfRankedFeatures(train_x, num_features, task, fileNames=defaultFileNames):\n",
    "    fileName = fileNames[task]\n",
    "    \n",
    "    with open(fileName) as f:\n",
    "        alist = [line.rstrip() for line in f]\n",
    "    all_indices_ranked = alist[0].split(',')\n",
    "    all_indices_ranked = [int(x) for x in all_indices_ranked]\n",
    "    all_indices_ranked = [x-1 for x in all_indices_ranked]    \n",
    "    xx = [all_indices_ranked[x] for x in range(0, num_features)]\n",
    "    xx = tuple(xx)\n",
    "    return xx    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSmallerTrainingSet(train_x, task, num_features, fileNames=defaultFileNames):\n",
    "    xx = getListOfRankedFeatures(train_x, num_features, task, fileNames)\n",
    "    smaller_train_x = train_x[:, xx]    \n",
    "    return smaller_train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doSVMwithPoly(train_x, train_y, task):\n",
    "    \"\"\"\n",
    "    params = {'age': {'degrees': [1,2,3],\n",
    "                      'C': [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4]},\n",
    "              'gender': {'degrees': [1,2,3],\n",
    "                      'C': [10**-4, 10**-1, 1, 10**1, 10**4]}\n",
    "             }\n",
    "    \"\"\"\n",
    "    \n",
    "    params = {'age': {'degrees': [1,2,3],\n",
    "                            'C': [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4]},\n",
    "              'gender': {'degrees': [1,2,3],\n",
    "                      'C': [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4] }\n",
    "             }\n",
    "    svm_poly_result = {}\n",
    "    \n",
    "    degrees = params[task]['degrees']\n",
    "    C = params[task]['C']\n",
    "    \n",
    "    list_of_scores = []\n",
    "    results_with_params = {}\n",
    "    for degree in degrees:\n",
    "        for one_C in C:\n",
    "            clf = svm.SVC(kernel='poly', degree=degree, coef0=one_C, gamma=1)\n",
    "            scoring_function = 'accuracy'\n",
    "            scores = cross_validation.cross_val_score(clf, smaller_train_x, train_y, cv=10, scoring=scoring_function)\n",
    "            list_of_scores.append(scores)\n",
    "            label = str(degree)+','+str(one_C)\n",
    "            results_with_params[label] = scores\n",
    "    \n",
    "    svm_poly_result_list_of_scores = list_of_scores\n",
    "    \n",
    "    return svm_poly_result_list_of_scores, results_with_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doFeatureWithClassOfOther(train_x, train_y_task, train_y_prior, task, optimal_params):\n",
    "    num_features_dict = {'age': 9000,\n",
    "                         'gender': 7000}\n",
    "    # optimal_params = {'age': ['poly', 3, 10, 1], 'gender': ['poly', 2, 10000, 1]}\n",
    "    \n",
    "    accuracies_dictionary = {}\n",
    "    \n",
    "    age_classification_kernel_type = optimal_params[\"age\"][0]\n",
    "    p1 = optimal_params[\"age\"][1]\n",
    "    p2 = optimal_params[\"age\"][2]\n",
    "    \n",
    "    gender_classification_kernel_type = optimal_params[\"age\"][0]\n",
    "    q1 = optimal_params[\"age\"][1]\n",
    "    q2 = optimal_params[\"age\"][2]\n",
    "    \n",
    "    \n",
    "    if age_classification_kernel_type == \"poly\":\n",
    "        clf_age_classification = svm.SVC(kernel='poly', degree=p1, coef0=p2, gamma=1)\n",
    "    else:\n",
    "        clf_age_classification = svm.SVC(kernel='rbf', degree=q1, gamma=q2)\n",
    "        \n",
    "        \n",
    "    if gender_classification_kernel_type == \"poly\":\n",
    "        clf_gender_classification = svm.SVC(kernel='poly', degree=p1, coef0=p2, gamma=1)\n",
    "    else:\n",
    "        clf_gender_classification = svm.SVC(kernel='rbf', degree=q1, gamma=q2)\n",
    "    \n",
    "\n",
    "    # age classification:\n",
    "    #    clf1 = svm.SVC(kernel='poly', degree=3, coef0=10, gamma=1)\n",
    "    \n",
    "    # gender classification:\n",
    "    #    clf2 = svm.SVC(kernel='poly', degree=2, coef0=10000, gamma=1)\n",
    "    \n",
    "    scoring_function = 'accuracy'\n",
    "    \n",
    "    if task == \"age\":\n",
    "        prior = \"gender\"\n",
    "        clf_prior = clf_gender_classification\n",
    "        clf_task = clf_age_classification\n",
    "    else:\n",
    "        prior = \"age\"\n",
    "        clf_prior = clf_age_classification\n",
    "        clf_task = clf_gender_classification\n",
    "\n",
    "    num_features_task = num_features_dict[task]\n",
    "    num_features_prior = num_features_dict[prior]\n",
    "    \n",
    "    # smaller_training_set_for_prior = getSmallerTrainingSet(train_x, task, num_features_prior) \n",
    "    smaller_training_set_for_task = getSmallerTrainingSet(train_x, task, num_features_task)\n",
    "    \n",
    "    # clf_prior.fit(smaller_training_set_for_prior, train_y_prior)\n",
    "    # results_prior = clf_prior.predict(smaller_training_set_for_prior)\n",
    "    \n",
    "    # combined = np.column_stack((smaller_training_set_for_task, results_prior))\n",
    "    combined = np.column_stack((smaller_training_set_for_task, train_y_prior))\n",
    "    \n",
    "    scores = cross_validation.cross_val_score(clf_task, combined, train_y_task, cv=10, scoring=scoring_function)\n",
    "    accuracies_dictionary[task] = scores\n",
    "    \n",
    "    return accuracies_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def doSVMwithPreprocessedText(train, task, num_features, optimal_params):\n",
    "    accuracy_dictionary = {}\n",
    "    \n",
    "    age_classification_kernel_type = optimal_params[\"age\"][0]\n",
    "    p1 = optimal_params[\"age\"][1]\n",
    "    p2 = optimal_params[\"age\"][2]\n",
    "    \n",
    "    gender_classification_kernel_type = optimal_params[\"age\"][0]\n",
    "    q1 = optimal_params[\"age\"][1]\n",
    "    q2 = optimal_params[\"age\"][2]\n",
    "    \n",
    "    \n",
    "    if age_classification_kernel_type == \"poly\":\n",
    "        clf_age_classification = svm.SVC(kernel='poly', degree=p1, coef0=p2, gamma=1)\n",
    "    else:\n",
    "        clf_age_classification = svm.SVC(kernel='rbf', degree=q1, gamma=q2)\n",
    "        \n",
    "        \n",
    "    if gender_classification_kernel_type == \"poly\":\n",
    "        clf_gender_classification = svm.SVC(kernel='poly', degree=p1, coef0=p2, gamma=1)\n",
    "    else:\n",
    "        clf_gender_classification = svm.SVC(kernel='rbf', degree=q1, gamma=q2)\n",
    "    \n",
    "    \n",
    "    newFileNames = {'age': 'new-age-important-words-using-info-gain.txt',\n",
    "                    'gender': 'new-gender-important-words-using-info-gain.txt'\n",
    "                    }\n",
    "    \n",
    "    train_y = train[task]\n",
    "    \n",
    "    clean_train_data = []\n",
    "    urls = []\n",
    "    hashtags = []\n",
    "    num_text = train[\"text\"].size\n",
    "    for i in xrange( 0, num_text):\n",
    "        one_clean_line = clean_text( train[\"text\"][i] )\n",
    "        new_clean_line = \"\"\n",
    "        #replacing links\n",
    "        url = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', one_clean_line)\n",
    "        for one_url in url:\n",
    "            new_clean_line = one_clean_line.replace(one_url, \" LINK_HERE \")\n",
    "            one_clean_line = new_clean_line\n",
    "        urls.append(url)\n",
    "    \n",
    "        hashtag = re.findall('#(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', one_clean_line)\n",
    "    \n",
    "        for one_hashtag in hashtag:\n",
    "            new_clean_line = one_clean_line.replace(one_hashtag, \" HASHTAG_HERE \")\n",
    "            one_clean_line = new_clean_line\n",
    "        \n",
    "        hashtags.append(hashtag)\n",
    "        clean_train_data.append( one_clean_line )\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None)\n",
    "    train_x = vectorizer.fit_transform(clean_train_data)\n",
    "    train_x = train_x.toarray()\n",
    "    \n",
    "    smaller_train_x = getSmallerTrainingSet(train_x, task, num_features, newFileNames)\n",
    "    \n",
    "    if task == \"age\":\n",
    "        clf = clf_age_classification\n",
    "    else:\n",
    "        clf = clf_gender_classification\n",
    "    \n",
    "    scores = cross_validation.cross_val_score(clf, smaller_train_x, train_y, cv=10, scoring='accuracy')\n",
    "    \n",
    "    accuracy_dictionary[task] = scores\n",
    "    return accuracy_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractMeanAccuraciesForPolyAndRBF(results, Cs=[], gammas=[]):\n",
    "    svm_mean_accuracy = {}\n",
    "    svm_list_of_accuracies = []\n",
    "    for gamma in gammas:\n",
    "        for C in Cs:\n",
    "            label = str(gamma)+\",\"+str(C)\n",
    "            svm_mean_accuracy[label] = results[label].mean()\n",
    "            svm_list_of_accuracies.append(results[label])\n",
    "    return svm_mean_accuracy, svm_list_of_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makePValMatrix(list_of_accuracies):\n",
    "    list_length = len(list_of_accuracies)\n",
    "    p_value_matrix = np.zeros((list_length, list_length))\n",
    "    i = range(0, list_length)\n",
    "    #sig values\n",
    "    for treatment1,x in zip(svm_poly_age_list_of_accuracies,i):\n",
    "        for treatment2,y in zip(svm_poly_age_list_of_accuracies,i):\n",
    "            z_stat, p_val = stats.ranksums(treatment1, treatment2)\n",
    "            p_value_matrix[x,y] = p_val\n",
    "    return p_value_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def turnPValMatrixToExcel(fileName, p_value_matrix, list_of_accuracies):\n",
    "    df = pd.DataFrame(data = p_value_matrix, columns=list_of_accuracies)\n",
    "    df.index = list_of_accuracies\n",
    "    null_disproved = df[df < 0.05]\n",
    "    null_disproved.to_csv(fileName, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-73a4ab1b3fd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mscoring_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mall_indices_ranked\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_info_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;31m#xx = tuple(xx)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m#smaller_train_x = train_x[:, xx]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tasks = [\"age\"]\n",
    "allResults = {}\n",
    "\n",
    "datafile = \"summary-english-truth.txt\"\n",
    "train = pd.read_csv(datafile, header=0, delimiter=\"\\t\", quoting=1)\n",
    "clean_train_data = clean_all_text(train[\"text\"], train[\"text\"].size)\n",
    "clean_train_data = train[\"text\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None)\n",
    "train_x = vectorizer.fit_transform(clean_train_data)\n",
    "train_x = train_x.toarray()\n",
    "\n",
    "rows, cols = train_x.shape\n",
    "top_info_words_numbers = [100, 200, 300, 500, 700, 1000, 2000, 5000, 7000, 8000, 9000, 10000, cols-1]\n",
    "top_info_words_numbers =  sorted(top_info_words_numbers, reverse=True)\n",
    "\n",
    "feature_selection_result = {}\n",
    "    \n",
    "task_to_filenames = {'age': ['age-important-words-using-info-gain.txt', \n",
    "                             'age-important-words-using-gain-ratio.txt'],\n",
    "                     'gender': ['gender-important-words-using-info-gain.txt', \n",
    "                                'gender-important-words-using-gain-ratio.txt']\n",
    "                    }\n",
    "    \n",
    "task_to_filenames = {'age': ['age-important-words-using-info-gain.txt'],\n",
    "                     'gender': ['gender-important-words-using-info-gain.txt']\n",
    "                    }\n",
    "    \n",
    "filenames = task_to_filenames[task]\n",
    "for filename in filenames:\n",
    "    with open(filename) as f:\n",
    "        alist = [line.rstrip() for line in f]\n",
    "    all_indices_ranked = alist[0].split(',')\n",
    "    all_indices_ranked = [int(x) for x in all_indices_ranked]\n",
    "    all_indices_ranked = [x-1 for x in all_indices_ranked]\n",
    "        \n",
    "#list_of_scores = []\n",
    "#    for num_info_words in top_info_words_numbers:\n",
    "#        clf = svm.SVC(kernel='linear', C=1)\n",
    "#        scoring_function = 'accuracy'\n",
    "            \n",
    "#        xx = [all_indices_ranked[x] for x in range(0, num_info_words)]\n",
    "    #xx = tuple(xx)\n",
    "    #smaller_train_x = train_x[:, xx]\n",
    "\n",
    "    #scores = cross_validation.cross_val_score(clf, smaller_train_x, train_y, cv=10, scoring=scoring_function)\n",
    "    #list_of_scores.append(scores)\n",
    "            \n",
    "#feature_selection_result[filename] = list_of_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1967"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_info_words\n",
    "len(all_indices_ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-934bc26a1735>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# experiment 1.1: Feature Selection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mfeature_selection_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatureSelection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0maccuracies_dictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetAccuracies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_selection_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mp_values_dictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculatePValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_selection_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-989ec524ed5d>\u001b[0m in \u001b[0;36mfeatureSelection\u001b[1;34m(train_x, task, train_y)\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mscoring_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mall_indices_ranked\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_info_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[0mxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0msmaller_train_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# MAIN STUFF\n",
    "\n",
    "tasks = [\"age\", \"gender\"]\n",
    "allResults = {}\n",
    "\n",
    "datafile = \"summary-english-truth.txt\"\n",
    "train = pd.read_csv(datafile, header=0, delimiter=\"\\t\", quoting=1)\n",
    "clean_train_data = clean_all_text(train[\"text\"], train[\"text\"].size)\n",
    "clean_train_data = train[\"text\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None)\n",
    "train_x = vectorizer.fit_transform(clean_train_data)\n",
    "train_x = train_x.toarray()\n",
    "\n",
    "\n",
    "for task in tasks:\n",
    "    train_y = train[task]\n",
    "\n",
    "    # experiment 1.1: Feature Selection\n",
    "    feature_selection_result = featureSelection(train_x, task, train_y)\n",
    "    accuracies_dictionary = getAccuracies(feature_selection_result)\n",
    "    p_values_dictionary = calculatePValue(feature_selection_result)\n",
    "\n",
    "    \n",
    "    label=task+\"-experiment-1.1\"\n",
    "    allResults[label] = feature_selection_result\n",
    "    # experiment 1.2: SVM Poly\n",
    "    num_features_dictionary = {'age': 9000,\n",
    "                               'gender': 7000\n",
    "                              }\n",
    "    num_features = num_features_dictionary[task]\n",
    "    smaller_train_x = getSmallerTrainingSet(train_x, task, num_features)\n",
    "\n",
    "    svm_poly_result_list_of_scores, svm_poly_results_with_params = doSVMwithPoly(smaller_train_x, train_y, task)\n",
    "    svm_poly_accuracies_dictionary = getAccuracies(svm_poly_results_with_params)\n",
    "    \n",
    "    label=task+\"-experiment-1.2\"\n",
    "    allResults[label] = svm_poly_results_with_params\n",
    "\n",
    "    #  experiment 1.3: SVM RBF\n",
    "    svm_rbf_result_list_of_scores, svm_rbf_results_with_params = doSVMwithRBF(smaller_train_x, train_y, task)\n",
    "    svm_rbf_accuracies_dictionary = getAccuracies(svm_rbf_results_with_params)\n",
    "\n",
    "    label=task+\"-experiment-1.3\"\n",
    "    allResults[label] = svm_rbf_results_with_params\n",
    "    \n",
    "    \n",
    "#    doRandomForest()\n",
    "#    doBoosting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optimal params taken when looking at stats from the others\n",
    "optimal_params = {'age': ['poly', 3, 10, 1], 'gender': ['rbf', 10, 1, 1]} \n",
    "for task in [\"age\", \"gender\"]:   \n",
    "    # experiment 2 7000 gender + age info, 9000 age + gender info\n",
    "    if task == \"age\":\n",
    "        prior = \"gender\"\n",
    "    else:\n",
    "        prior = \"age\"\n",
    "    \n",
    "    train_y_task = train[task]\n",
    "    train_y_prior = train[prior]\n",
    "    res_for_other = doFeatureWithClassOfOther(train_x, train_y_task, train_y_prior, task, optimal_params)\n",
    "they \n",
    "    label=task+\"-experiment-2\"\n",
    "    allResults[label] = res_for_other\n",
    "\n",
    "    # experiment 3: turning hashtags/hyperlinks to HASHTAG_HERE and LINK_HERE\n",
    "    \n",
    "    res_with_preprocessed_text = doSVMwithPreprocessedText(train, task, num_features, optimal_params)\n",
    "    \n",
    "    label=task+\"-experiment-3\"\n",
    "    allResults[label] = res_with_preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#part where we change compare results\n",
    "\n",
    "# Experiment 1.1: feature selection\n",
    "\n",
    "results = allResults[\"age-experiment-1.1\"]\n",
    "age_feat_select_accuracies_dictionary = getAccuracies(results)\n",
    "age_feat_select_p_values_dictionary = calculatePValue(results)\n",
    "\n",
    "results = allResults[\"gender-experiment-1.1\"]\n",
    "gender_feat_select_accuracies_dictionary = getAccuracies(results)\n",
    "gender_feat_select_p_values_dictionary = calculatePValue(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment 1.2: SVM Poly \n",
    "\n",
    "# Age\n",
    "results = allResults[\"age-experiment-1.2\"]\n",
    "\n",
    "# getting mean accuracy for each and putting in a dictionary        \n",
    "svm_poly_age_mean_accuracy, svm_poly_age_list_of_accuracies = extractMeanAccuraciesForPolyAndRBF(results, [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4] , [1,2,3])\n",
    "svm_poly_age_mean_accuracy = [a.mean() for a in svm_poly_age_list_of_accuracies]\n",
    "p_val_matrix = makePValMatrix(svm_poly_age_list_of_accuracies)\n",
    "turnPValMatrixToExcel(\"pval-null-disproved-age-poly.csv\", p_val_matrix, svm_poly_age_mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gender\n",
    "results = allResults[\"gender-experiment-1.2\"]\n",
    "svm_poly_gender_mean_accuracy, svm_poly_gender_list_of_accuracies = extractMeanAccuraciesForPolyAndRBF(results, [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4] , [1,2,3])\n",
    "svm_poly_gender_mean_accuracy = [a.mean() for a in svm_poly_gender_list_of_accuracies]\n",
    "p_val_matrix = makePValMatrix(svm_poly_gender_list_of_accuracies)\n",
    "turnPValMatrixToExcel(\"pval-null-disproved-gender-poly.csv\", p_val_matrix, svm_poly_gender_mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment 1.3: SVM RBF \n",
    "\n",
    "# Age\n",
    "results = allResults[\"age-experiment-1.3\"]\n",
    "svm_rbf_age_mean_accuracy, svm_rbf_age_list_of_accuracies = extractMeanAccuraciesForPolyAndRBF(results, [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4] , [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4] )\n",
    "svm_rbf_age_mean_accuracy = [a.mean() for a in svm_rbf_age_list_of_accuracies]\n",
    "p_val_matrix = makePValMatrix(svm_rbf_age_list_of_accuracies)\n",
    "turnPValMatrixToExcel(\"pval-null-disproved-age-rbf.csv\", p_val_matrix, svm_rbf_age_mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gender\n",
    "results = allResults[\"gender-experiment-1.3\"]\n",
    "svm_rbf_gender_mean_accuracy, svm_rbf_gender_list_of_accuracies = extractMeanAccuraciesForPolyAndRBF(results, [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4] , [10**-4, 10**-3, 10**-1, 1, 10**1, 10**3, 10**4] )\n",
    "svm_rbf_gender_mean_accuracy = [a.mean() for a in svm_rbf_gender_list_of_accuracies]\n",
    "p_val_matrix = makePValMatrix(svm_rbf_gender_list_of_accuracies)\n",
    "turnPValMatrixToExcel(\"pval-null-disproved-gender-rbf.csv\", p_val_matrix, svm_rbf_gender_mean_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment 2: Using the other classification result as prior\n",
    "# Age\n",
    "age_classification_results_with_priors = allResults[\"age-experiment-2\"][\"age\"]\n",
    "best_result_age_classification = allResults[\"age-experiment-1.2\"]['3,10']\n",
    "z_stat, p_val = stats.ranksums(age_classification_results_with_priors, best_result_age_classification)\n",
    "[age_classification_results_with_priors.mean(), best_result_age_classification.mean(), p_val]\n",
    "\n",
    "\n",
    "# similar since greater than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gender\n",
    "gender_classification_results_with_priors = allResults[\"gender-experiment-2\"][\"gender\"]\n",
    "best_result_gender_classification = allResults[\"gender-experiment-1.3\"]['1,10']\n",
    "z_stat, p_val = stats.ranksums(gender_classification_results_with_priors, best_result_gender_classification)\n",
    "[gender_classification_results_with_priors.mean(), best_result_gender_classification.mean(), p_val]\n",
    "\n",
    "# similar since greater than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment 3: Different text\n",
    "# Age\n",
    "age_classification_with_string_sub = allResults[\"age-experiment-3\"][\"age\"]\n",
    "best_result_age_classification = allResults[\"age-experiment-1.2\"]['3,10']\n",
    "z_stat, p_val = stats.ranksums(age_classification_with_string_sub, best_result_age_classification)\n",
    "[age_classification_with_string_sub.mean(), best_result_age_classification.mean(), p_val]\n",
    "# similar since greater than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gender\n",
    "gender_classification_with_string_sub = allResults[\"gender-experiment-3\"][\"gender\"]\n",
    "best_result_gender_classification = allResults[\"gender-experiment-1.3\"]['1,10']\n",
    "z_stat, p_val = stats.ranksums(gender_classification_with_string_sub, best_result_gender_classification)\n",
    "[gender_classification_with_string_sub.mean(), best_result_gender_classification.mean(), p_val]\n",
    "# similar since greater than 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Additional comparisons:\n",
    "# Comparing age_classification_results_with_priors and best_of_age_classification\n",
    "z_stat, p_val = stats.ranksums(age_classification_results_with_priors, best_result_age_classification)\n",
    "[ age_classification_results_with_priors.mean(), best_result_age_classification.mean(), p_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Comparing gender_classification_results_with_priors and best_of_gender_classification\n",
    "z_stat, p_val = stats.ranksums(gender_classification_results_with_priors, best_result_gender_classification)\n",
    "[ gender_classification_results_with_priors.mean(), best_result_gender_classification.mean(), p_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment 4: Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "num_estimators = [10, 100, 1000, 2000, 5000, 10000]\n",
    "\n",
    "for task in [\"age\", \"gender\"]:\n",
    "    oneResult = {}\n",
    "    for x in num_estimators:\n",
    "        train_y = train[task]\n",
    "        clf = RandomForestClassifier(n_estimators=x)\n",
    "        scores = cross_validation.cross_val_score(clf, train_x, train_y, cv=10, scoring='accuracy')\n",
    "        oneResult[str(x)] = scores\n",
    "    label = task+\"-experiment-4\"\n",
    "    allResults[label] = oneResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [(a, allResults[\"age-experiment-4\"][a].mean()) for a in allResults[\"age-experiment-4\"].keys()] \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [(a, allResults[\"gender-experiment-4\"][a].mean()) for a in allResults[\"gender-experiment-4\"].keys()] \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Experiment 5: AdaBoost\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#num_estimators = [10, 100, 1000, 10000, 100000]\n",
    "num_estimators = [50, 100, 150, 200, 250]\n",
    "\n",
    "for task in [\"age\", \"gender\"]:\n",
    "    oneResult = {}\n",
    "    for x in num_estimators:\n",
    "        train_y = train[task]\n",
    "        clf = AdaBoostClassifier(n_estimators=x)\n",
    "        scores = cross_validation.cross_val_score(clf, train_x, train_y, cv=10, scoring='accuracy')\n",
    "        oneResult[str(x)] = scores\n",
    "    label = task+\"-experiment-5\"\n",
    "    allResults[label] = oneResult    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [(a, allResults[\"age-experiment-5\"][a].mean()) for a in allResults[\"age-experiment-5\"].keys()]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [(a, allResults[\"gender-experiment-5\"][a].mean()) for a in allResults[\"gender-experiment-5\"].keys()]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# STATISTICAL TESTS ON ENSEMBLE METHODS\n",
    "z_stat, p_val = stats.ranksums(allResults[\"gender-experiment-5\"]['200'], allResults[\"gender-experiment-5\"]['100'])\n",
    "p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [(a, allResults[\"age-experiment-5\"][a].mean()) for a in allResults[\"age-experiment-5\"].keys()]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# COMPARISON BETWEEN SVM WITH X, Y, Z params with Random Forest\n",
    "# AGE\n",
    "best_result_age_classification = allResults[\"age-experiment-1.2\"]['3,10']\n",
    "best_result_age_random_forest = allResults[\"age-experiment-4\"]['10000']\n",
    "z_stat, p_val = stats.ranksums(best_result_age_random_forest, best_result_age_classification)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GENDER\n",
    "best_result_gender_classification = allResults[\"gender-experiment-1.3\"]['1,10']\n",
    "best_result_gender_random_forest = allResults[\"gender-experiment-4\"]['1000'] \n",
    "z_stat, p_val = stats.ranksums(best_result_gender_random_forest, best_result_gender_classification)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# COMPARISON BETWEEN SVM WITH X, Y, Z params with AdaBoost\n",
    "# AGE\n",
    "best_result_age_classification = allResults[\"age-experiment-1.2\"]['3,10']\n",
    "best_result_age_adaboost = allResults[\"age-experiment-5\"]['50']\n",
    "z_stat, p_val = stats.ranksums(best_result_age_adaboost, best_result_age_classification)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GENDER\n",
    "best_result_gender_classification = allResults[\"gender-experiment-1.3\"]['1,10']\n",
    "best_result_gender_adaboost = allResults[\"gender-experiment-5\"]['200'] \n",
    "z_stat, p_val = stats.ranksums(best_result_gender_adaboost, best_result_gender_classification)\n",
    "p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_result_age_random_forest = allResults[\"age-experiment-4\"]['1000']\n",
    "best_result_age_random_forest.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
